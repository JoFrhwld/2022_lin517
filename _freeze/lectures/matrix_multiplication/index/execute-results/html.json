{
  "hash": "11c2bc6cba8987b010f48b69395ea043",
  "result": {
    "markdown": "---\ntitle: \"Matrix Multiplication\"\nauthor: \"Josef Fruehwald\"\ndate: \"2022-11-16\"\ncategories:\n  - \"Neural Networks\"\neditor: visual\n---\n\n\nIn the lecture notes on [gradient descent](../gradient_descent/01_gradient_descent.qmd), we already saw the use of matrix multiplication used to do linear regression, and I framed it as a kind of extension of dot products. Let's expand upon that.\n\n## What is Matrix Multiplication used for?\n\nMatrix multiplication is what makes almost everything work.\n\n``` python\nfor thing in set_of_all_things:\n   if matrix_multiplication in thing:\n      works = True\n    else:\n      works = Maybe?\n```\n\nIt's so fundamental to so many areas of mathematics, statistics, machine learning, etc this is how mathematicians talk about trying to discover new matrix multiplication algorithms:\n\n> \"It's hard to distinguish scientific thinking from wishful thinking,\" said [Chris Umans](http://users.cms.caltech.edu/~umans/) of the California Institute of Technology. \"I want the exponent to be two because it's beautiful.\"\n>\n> \"Exponent two\" refers to the ideal speed --- in terms of number of steps required --- of performing one of the most fundamental operations in math: matrix multiplication. If exponent two is achievable, then it's possible to carry out matrix multiplication as fast as physically possible. If it's not, then we're stuck in a world misfit to our dreams. ---[*Quanta Magazine*](https://www.quantamagazine.org/mathematicians-inch-closer-to-matrix-multiplication-goal-20210323/)\n\nAny regression model, principle components analysis, neural network, word2vec model, automatic speech recognition, self driving car, and even this rotating map of Kentucky, all use matrix multiplication for their basic operation.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.gif)\n:::\n:::\n\n\n## How does it work?\n\nWe'll be using numpy to do matrix multiplication, and we'll revisit the task of converting heights in feet and inches to centimeters. To convert feet to centimeters, we need to multiply it by 30.48, and to convert inches to centimeters, we need to multiply them by 2.54. Let's set up a column vector with these values\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfoot_in_tocm = np.array([[30.48], \n                         [ 2.54]])\nfoot_in_tocm                         \n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[30.48],\n       [ 2.54]])\n```\n:::\n:::\n\n\nI've called it a \"column\" vector, because it a actually has two rows, and one column.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfoot_in_tocm.shape\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(2, 1)\n```\n:::\n:::\n\n\nAnd let's set up a matrix of heights in feet and inches for an away mission with Jen Luc Picard, Lt. Data, and Deanna Troi. We'll have one row per away team member, and one column for the foot component of their height and another for the inches component of their height.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nheights_ft = np.array([[5, 10],\n                       [5, 11],\n                       [5,  5]])\n```\n:::\n\n\nIn order to convert each away team member's height into centimeters, we need to\n\n-   Multiply their feet component by 30.48\n\n-   Multiply their inches component by 2.54\n\n-   Sum the result.\n\na.k.a a dot product. We've got heights as rows...\n\n\n::: {.cell}\n\n```{.python .cell-code}\nheights_ft[0, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 5, 10])\n```\n:::\n:::\n\n\n... and the conversion factors as columns...\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfoot_in_tocm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[30.48],\n       [ 2.54]])\n```\n:::\n:::\n\n\nBut this is the *usual* organization of values for doing a dot product. You take the values across columns of matrix A, multiply them by the values across rows in matrix B, and sum up the result.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnp.dot(heights_ft[0, ], foot_in_tocm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([177.8])\n```\n:::\n:::\n\n\nSo, Jean Luc Picard is 177.8 centimeters tall. If we take the dot product of the whole `heights_ft` matrix, without doing any indexing, and `foot_in_tocm` we'll get back a column vector of every away team member's height.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnp.dot(heights_ft, foot_in_tocm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[177.8 ],\n       [180.34],\n       [165.1 ]])\n```\n:::\n:::\n\n\nThere's also a convenience operator built in to do matrix multiplication: `@`\n\n\n::: {.cell}\n\n```{.python .cell-code}\nheights_ft @ foot_in_tocm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[177.8 ],\n       [180.34],\n       [165.1 ]])\n```\n:::\n:::\n\n\n### What just happened.\n\nMatrix multiplication goes rowwise down the first matrix, and pulls out a row. Then it takes the dot product of that row and the first column of the second matrix. Then, the result gets saved as the first row, first column of the result matrix.\n\n![](assets/matmul.gif){fig-align=\"center\"}\n\n### Some rules for matrix multiplication\n\nMatrix multiplication isn't \"commutative\". That is to say, while `heights_ft @ foot_in_tocm` works, if we flipped the arguments to `foot_in_tocm @ heights_ft`, we'll get an error.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\nfoot_in_tocm @ heights_ft\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in py_call_impl(callable, dots$args, dots$keywords): ValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 1)\n```\n:::\n:::\n\n\nThis is because the number of columns in the first matrix always need to match the number of rows in the second matrix. You can kind of visualize this requirement by lining up the matrix `.shape`s like this:\n\n    âœ… Good!\n    Matrix A shape    (3,   2)\n    Matrix B Shape         (2,   1)\n\n    ðŸš« Bad!\n    Matrix B shape   (2,   1)\n    Matrix A shpe         (2,   3)\n\nThe resulting matrix will have the same number of rows from matrix A and the same number of columns as matrix B, which we can also visualize like this:\n\n    Matrix A shape    (3,   2)\n    Matrix B Shape         (2,   1)\n    Result Shape      (3,        1)\n\n### A more interesting conversion matrix\n\nTo convert feet and inches in to centimeters, we created a matrix with a two rows, and one column. Let's say we wanted to simultaneously convert the crew's heights into meters and into yards. We just need to add columns to the conversion matrix with what we need to multiply feet and inches by for these other measurement units.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n##                          cm      m      yd                         \nfoot_in_other = np.array([[30.48, 0.3048, 1/3],   # foot multiplier\n                          [2.54,  0.0254, 1/36]]) # inch multiplier\n```\n:::\n\n\nThen, we matrix multiply the\n\n\n::: {.cell}\n\n```{.python .cell-code}\nheights_ft @ foot_in_other\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[177.8       ,   1.778     ,   1.94444444],\n       [180.34      ,   1.8034    ,   1.97222222],\n       [165.1       ,   1.651     ,   1.80555556]])\n```\n:::\n:::\n\n\n## The way this relates to neural networks\n\nLet's start with an imaginary task of trying to guess which species a penguin is, based on one of 4 body measurements. This code loads the penguins data set and pulls out a matrix of the body length measures, and a vector of species.\n\n::: callout-note\nThe `peng` dataset is in a format called a pandas dataframe that we haven't gotten a chance to learn about yet.\n:::\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom palmerpenguins import load_penguins\npeng = load_penguins()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nbody_meas = peng[[\"bill_length_mm\", \"bill_depth_mm\", \n                  \"flipper_length_mm\", \"body_mass_g\"]].\\\n                  dropna()\nspecies = peng.dropna()[\"species\"]\n```\n:::\n\n\nLet's pull out one row of body measurements for an individual penguin\n\n\n::: {.cell}\n\n```{.python .cell-code}\none_penguin = np.array(body_meas)[0,:]\none_penguin\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([  39.1,   18.7,  181. , 3750. ])\n```\n:::\n:::\n\n\nWith our neural network, we'll want to use these 4 Input values to try to predict which one of 3 species this individual penguin is, ad we'll try to do that with a \"hidden\" layer of 10 nodes. That kind of model is conventionally represented like so:\n\n![](assets/nn.svg){fig-align=\"center\"}\n\nTo get the value that's supposed to be in the first hidden layer node, we multiply each of the 4 body measurement by some number, then sum them together.\n\n![](assets/nod1.svg){fig-align=\"center\" width=\"400\"}\n\nThat should be starting to sound like a familiar process! To do that for a single node, we just do a dot product, but to repeat it simultaneously for all hidden layer nodes, we need a matrix of weights to do matrix multiplication with. To work out the shape of the matrix we need, we can go back to thinking about how the shapes of the matrices we multiply relate to the outputs\n\n    Input shape      (1,     4)\n    weights shape?          (?,     ?)\n    hidden shape     (1,           10)\n\nIt looks like we need a 4 by 10 matrix to convert the 4 input data dimensions into 10 hidden dimensions.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nto_hidden_layer = np.random.random((4, 10))\nhidden_layer = one_penguin @ to_hidden_layer\nhidden_layer\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([1680.05479008, 1044.57772039,  844.75218032,  173.76123438,\n       3648.58188585, 3714.92000402,  240.29638976,  418.92577036,\n       1545.41450822, 2795.51178638])\n```\n:::\n:::\n\n\nThen, we need translate the values for these 10 hidden nodes into 3 values for the output nodes.\n\n    hidden shape      (1,   10)\n    weights shape?         ( ?    ?)\n    output shape      (1,         3)\n\nLooks like we'll need a 10 by 3 matrix.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nto_output = np.random.random((10, 3))\noutput = hidden_layer @ to_output\noutput\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([7768.61330139, 8201.82309701, 7851.91440961])\n```\n:::\n:::\n\n\nAnd then, we'd probably convert the output to probabilities using softmax, and whichever node has the largest probability we choose as the species.\n\n### Things to note\n\nFirst, a nifty thing is that the matrices we created to convert one penguin's data to 3 output nodes will work just as well converting an arbitrary number of penguin's data to output nodes.\n\n    input            (N,  4)\n    hidden weights       (4, 10)\n    hidden nodes     (N,     10)\n    output weights          (10, 3)\n    output           (N,          3)\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnp.array(body_meas)[0:6, ] @ to_hidden_layer @ to_output\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[7768.61330139, 8201.82309701, 7851.91440961],\n       [7874.20887775, 8312.9173626 , 7958.17552609],\n       [6826.68067025, 7191.24211381, 6881.39217186],\n       [7204.24658538, 7597.0022168 , 7269.85071435],\n       [7595.77456845, 8013.83171594, 7670.35667202],\n       [7523.75929824, 7940.82374454, 7601.66414793]])\n```\n:::\n:::\n\n\nThe second thing to note is that these numbers we just got, based on random weights in the matrices, are obviously bad. But, they can be improved with [gradient descent](%22../gradient_descent/01_gradient_descent.qmd%22)!\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}